#!/usr/bin/env python3
"""
Batch TTS generator - Process multiple texts efficiently with OpenAI TTS
Perfect for pre-generating common notifications and saving costs
"""

import os
import sys
import json
import hashlib
import argparse
import requests
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional

# Try to import our cache manager
sys.path.insert(0, str(Path(__file__).parent / 'tts'))
try:
    from cache_manager import TTSCache
    from usage_tracker import UsageTracker
    TRACKING_AVAILABLE = True
except ImportError:
    TRACKING_AVAILABLE = False
    print("Warning: Cache/tracking not available", file=sys.stderr)


class BatchTTSGenerator:
    """Generate TTS audio in batch for cost efficiency."""
    
    def __init__(self, api_key: Optional[str] = None, output_dir: str = "tts_output"):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OpenAI API key required. Set OPENAI_API_KEY environment variable.")
        
        self.api_url = "https://api.openai.com/v1/audio/speech"
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # Initialize cache and tracker if available
        self.cache = TTSCache() if TRACKING_AVAILABLE else None
        self.tracker = UsageTracker() if TRACKING_AVAILABLE else None
        
        # Track session stats
        self.session_stats = {
            'processed': 0,
            'cached': 0,
            'generated': 0,
            'failed': 0,
            'total_chars': 0,
            'total_cost': 0.0,
            'cache_savings': 0.0
        }
    
    def generate_filename(self, text: str, idx: int) -> str:
        """Generate a descriptive filename from text."""
        # Create a short, filesystem-safe version of the text
        safe_text = text[:30].lower()
        safe_text = ''.join(c if c.isalnum() or c in ' -_' else '' for c in safe_text)
        safe_text = safe_text.strip().replace(' ', '_')
        
        # Add index for uniqueness
        return f"{idx:03d}_{safe_text}.mp3"
    
    def check_cache(self, text: str, voice: str) -> Optional[Path]:
        """Check if we have this text cached."""
        if not self.cache:
            return None
        
        cached_path = self.cache.get_audio_path(text, 'openai', voice)
        if cached_path:
            return Path(cached_path)
        return None
    
    def generate_single(self, text: str, voice: str = "onyx", 
                       model: str = "tts-1", idx: int = 1) -> Dict:
        """Generate TTS for a single text."""
        result = {
            'text': text,
            'success': False,
            'cached': False,
            'output_path': None,
            'error': None,
            'cost': 0.0
        }
        
        # Check cache first
        cached_path = self.check_cache(text, voice)
        if cached_path:
            # Copy cached file to output directory
            output_filename = self.generate_filename(text, idx)
            output_path = self.output_dir / output_filename
            
            try:
                import shutil
                shutil.copy2(cached_path, output_path)
                result['success'] = True
                result['cached'] = True
                result['output_path'] = str(output_path)
                self.session_stats['cached'] += 1
                
                # Track cache savings
                if self.tracker:
                    cost = self.tracker.estimate_cost('openai', len(text), model)
                    self.session_stats['cache_savings'] += cost
                
                return result
            except Exception as e:
                print(f"Warning: Could not copy cached file: {e}", file=sys.stderr)
        
        # Generate new audio
        payload = {
            "model": model,
            "input": text,
            "voice": voice
        }
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        try:
            response = requests.post(self.api_url, headers=headers, json=payload, timeout=30)
            
            if response.status_code == 200:
                # Save audio
                output_filename = self.generate_filename(text, idx)
                output_path = self.output_dir / output_filename
                
                audio_data = response.content
                with open(output_path, 'wb') as f:
                    f.write(audio_data)
                
                result['success'] = True
                result['output_path'] = str(output_path)
                self.session_stats['generated'] += 1
                
                # Cache the audio
                if self.cache:
                    self.cache.save_audio(text, 'openai', audio_data, voice)
                
                # Track usage
                if self.tracker:
                    cost, _ = self.tracker.track_usage('openai', text, model=model)
                    result['cost'] = cost
                    self.session_stats['total_cost'] += cost
                
            else:
                result['error'] = f"API error {response.status_code}: {response.text}"
                self.session_stats['failed'] += 1
                
        except requests.exceptions.Timeout:
            result['error'] = "Request timed out"
            self.session_stats['failed'] += 1
        except Exception as e:
            result['error'] = f"Error: {str(e)}"
            self.session_stats['failed'] += 1
        
        return result
    
    def process_file(self, input_file: str, voice: str = "onyx", 
                    model: str = "tts-1", manifest: bool = True) -> Dict:
        """Process all lines in a text file."""
        input_path = Path(input_file)
        if not input_path.exists():
            raise FileNotFoundError(f"Input file not found: {input_file}")
        
        # Read all lines
        with open(input_path, 'r', encoding='utf-8') as f:
            lines = [line.strip() for line in f if line.strip()]
        
        print(f"\nðŸŽ¯ Processing {len(lines)} lines from {input_file}")
        print(f"ðŸ“‚ Output directory: {self.output_dir}")
        print(f"ðŸŽ¤ Voice: {voice}, Model: {model}")
        print("-" * 50)
        
        results = []
        manifest_data = {
            'generated': datetime.now().isoformat(),
            'source_file': str(input_path),
            'voice': voice,
            'model': model,
            'items': []
        }
        
        # Process each line
        for idx, text in enumerate(lines, start=1):
            self.session_stats['processed'] += 1
            self.session_stats['total_chars'] += len(text)
            
            # Show progress
            print(f"\n[{idx}/{len(lines)}] Processing: {text[:50]}...")
            
            result = self.generate_single(text, voice, model, idx)
            results.append(result)
            
            if result['success']:
                if result['cached']:
                    print(f"  âœ… Using cached audio: {result['output_path']}")
                else:
                    print(f"  âœ… Generated: {result['output_path']} (${result['cost']:.4f})")
                
                manifest_data['items'].append({
                    'index': idx,
                    'text': text,
                    'file': os.path.basename(result['output_path']),
                    'cached': result['cached'],
                    'cost': result['cost']
                })
            else:
                print(f"  âŒ Failed: {result['error']}")
        
        # Save manifest if requested
        if manifest:
            manifest_path = self.output_dir / "manifest.json"
            with open(manifest_path, 'w') as f:
                json.dump(manifest_data, f, indent=2)
            print(f"\nðŸ“‹ Manifest saved: {manifest_path}")
        
        return {
            'results': results,
            'stats': self.session_stats
        }
    
    def process_list(self, texts: List[str], voice: str = "onyx", 
                    model: str = "tts-1") -> Dict:
        """Process a list of texts."""
        results = []
        
        for idx, text in enumerate(texts, start=1):
            self.session_stats['processed'] += 1
            self.session_stats['total_chars'] += len(text)
            
            result = self.generate_single(text, voice, model, idx)
            results.append(result)
        
        return {
            'results': results,
            'stats': self.session_stats
        }
    
    def show_summary(self):
        """Show processing summary."""
        print("\n" + "=" * 50)
        print("ðŸ“Š Batch Processing Summary")
        print("=" * 50)
        print(f"Total processed: {self.session_stats['processed']}")
        print(f"  âœ… Generated: {self.session_stats['generated']}")
        print(f"  ðŸ’¾ From cache: {self.session_stats['cached']}")
        print(f"  âŒ Failed: {self.session_stats['failed']}")
        print(f"\nTotal characters: {self.session_stats['total_chars']:,}")
        print(f"Generation cost: ${self.session_stats['total_cost']:.4f}")
        print(f"Cache savings: ${self.session_stats['cache_savings']:.4f}")
        print(f"Net cost: ${self.session_stats['total_cost'] - self.session_stats['cache_savings']:.4f}")
        
        # Show per-item cost
        if self.session_stats['generated'] > 0:
            avg_cost = self.session_stats['total_cost'] / self.session_stats['generated']
            print(f"\nAverage cost per item: ${avg_cost:.4f}")


def create_common_notifications():
    """Create a file with common developer notifications."""
    common_file = Path("common_notifications.txt")
    
    notifications = [
        # Build/Compile
        "Build complete",
        "Build failed",
        "Compilation successful",
        "Compilation error detected",
        
        # Testing
        "All tests passed",
        "Tests failed",
        "Test suite complete",
        "Unit tests passed",
        
        # Deployment
        "Deployment successful",
        "Deployment failed",
        "Deploy in progress",
        "Rollback initiated",
        
        # Errors/Warnings
        "Error detected",
        "Warning",
        "Critical error",
        "Process failed",
        
        # Success/Status
        "Success",
        "Complete",
        "Ready",
        "Done",
        "Task finished",
        "Process complete",
        
        # Git/Version Control
        "Commit successful",
        "Push complete",
        "Merge conflict detected",
        "Pull request ready",
        
        # General
        "New notification",
        "Update available",
        "Download complete",
        "Upload finished",
        "Sync complete"
    ]
    
    with open(common_file, 'w') as f:
        for notification in notifications:
            f.write(notification + '\n')
    
    print(f"Created {common_file} with {len(notifications)} common notifications")
    return str(common_file)


def main():
    parser = argparse.ArgumentParser(
        description='Batch TTS Generator - Cost-effective audio generation with OpenAI',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Process a file with default settings
  speak-batch messages.txt
  
  # Use a specific voice
  speak-batch messages.txt --voice echo
  
  # Generate common developer notifications
  speak-batch --common
  
  # Use HD model for better quality
  speak-batch messages.txt --model tts-1-hd
  
  # Custom output directory
  speak-batch messages.txt --output audio_files
        """
    )
    
    parser.add_argument('input_file', nargs='?', 
                       help='Text file with one message per line')
    parser.add_argument('--voice', default='onyx',
                       choices=['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer'],
                       help='Voice to use (default: onyx)')
    parser.add_argument('--model', default='tts-1',
                       choices=['tts-1', 'tts-1-hd'],
                       help='Model to use (default: tts-1)')
    parser.add_argument('--output', default='tts_output',
                       help='Output directory (default: tts_output)')
    parser.add_argument('--common', action='store_true',
                       help='Generate common developer notifications')
    parser.add_argument('--no-manifest', action='store_true',
                       help='Skip creating manifest.json')
    
    args = parser.parse_args()
    
    # Handle --common flag
    if args.common:
        input_file = create_common_notifications()
    elif args.input_file:
        input_file = args.input_file
    else:
        parser.error("Either provide an input file or use --common flag")
    
    # Create generator
    try:
        generator = BatchTTSGenerator(output_dir=args.output)
    except ValueError as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)
    
    # Process file
    try:
        generator.process_file(
            input_file,
            voice=args.voice,
            model=args.model,
            manifest=not args.no_manifest
        )
        
        # Show summary
        generator.show_summary()
        
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()